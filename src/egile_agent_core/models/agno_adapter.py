"""Adapter to make Egile LLM models compatible with Agno's model interface."""

from __future__ import annotations

import json
import logging
from typing import TYPE_CHECKING, Any, AsyncIterator, Callable, Iterator

from agno.models.base import Model, Message
from agno.models.response import ModelResponse

if TYPE_CHECKING:
    from egile_agent_core.models.base import BaseLLM

logger = logging.getLogger(__name__)


class AgnoModelAdapter(Model):
    """
    Adapter that wraps Egile LLM models to work with Agno's Agent framework.
    
    This allows using egile-agent-core's multi-provider LLM support (XAI, OpenAI, 
    Azure, Mistral) within Agno's AgentOS.
    
    Example:
        ```python
        from egile_agent_core.models import XAI
        from egile_agent_core.models.agno_adapter import AgnoModelAdapter
        from agno.agent import Agent
        
        egile_model = XAI(model="grok-4-1-fast-reasoning")
        agno_model = AgnoModelAdapter(egile_model)
        
        agent = Agent(
            name="my-agent",
            model=agno_model,
            instructions=["You are a helpful assistant."],
        )
        ```
    """

    def __init__(self, egile_model: BaseLLM, tools: list[Callable] | None = None):
        """
        Initialize the adapter with an Egile LLM model.
        
        Args:
            egile_model: Any BaseLLM implementation from egile_agent_core.models
            tools: Optional list of callable tool functions for execution
        """
        self.egile_model = egile_model
        self._tool_map: dict[str, Callable] = {}  # Store tools by name for execution
        
        # Store tools if provided
        if tools:
            for tool in tools:
                if callable(tool):
                    self._tool_map[tool.__name__] = tool
                    logger.info(f"ðŸ”§ Registered tool in adapter: {tool.__name__}")
        
        super().__init__(
            id=egile_model.model,
            name=egile_model.model_name,
            provider=egile_model.provider_name,
        )

    def to_dict(self) -> dict[str, Any]:
        """Return model configuration as dictionary."""
        return {
            "id": self.id,
            "name": self.name,
            "provider": self.provider,
            "egile_model": self.egile_model.model,
            "temperature": self.egile_model.temperature,
        }
    
    def _get_tools_for_api(self, tools: list[Any] | None) -> list[dict[str, Any]] | None:
        """Convert Agno tools (callables or dicts) to OpenAI API format."""
        if not tools:
            return None
        
        api_tools = []
        for tool in tools:
            if isinstance(tool, dict):
                # Already in API format
                api_tools.append(tool)
            elif callable(tool):
                # Convert function to API format
                # Agno functions have __tool_spec__ attribute with OpenAI format
                if hasattr(tool, '__tool_spec__'):
                    api_tools.append(tool.__tool_spec__)
                else:
                    logger.warning(f"Tool {tool.__name__} has no __tool_spec__")
        
        return api_tools if api_tools else None

    def invoke(self, messages: list[Message]) -> str:
        """
        Synchronous invoke - not used, raises NotImplementedError.
        Agno prefers async methods.
        """
        raise NotImplementedError("Use ainvoke instead")

    def invoke_stream(self, messages: list[Message]) -> Iterator[ModelResponse]:
        """
        Synchronous stream - not used, raises NotImplementedError.
        Agno prefers async methods.
        """
        raise NotImplementedError("Use ainvoke_stream instead")

    async def ainvoke(self, messages: list[Message], **kwargs: Any) -> str:
        """
        Invoke the model with messages and return the response.
        
        Args:
            messages: List of Agno Message objects.
            **kwargs: Additional arguments from Agno (may include tools, functions, etc.).
            
        Returns:
            The assistant's response content.
        """
        # Convert Agno messages to egile format
        egile_messages = []
        
        # Handle different message formats
        if not isinstance(messages, list):
            messages = [messages]
            
        for msg in messages:
            if isinstance(msg, str):
                # String message - treat as user message
                egile_messages.append({"role": "user", "content": msg})
            elif isinstance(msg, dict):
                # Already a dictionary
                egile_messages.append(msg)
            elif hasattr(msg, 'role') and hasattr(msg, 'content'):
                # Message object with role and content attributes
                egile_messages.append({"role": msg.role, "content": msg.content})
            elif hasattr(msg, 'model_dump'):
                # Pydantic model
                egile_messages.append(msg.model_dump())
            else:
                # Fallback - convert to string and treat as user message
                egile_messages.append({"role": "user", "content": str(msg)})
        
        # Extract tools from kwargs if provided by Agno
        tools = kwargs.get('tools') or kwargs.get('functions')
        
        # Log for debugging
        logger.info(f"ðŸŽ¬ AgnoAdapter.ainvoke called with {len(egile_messages)} messages")
        logger.info(f"ðŸŽ¬ kwargs keys: {list(kwargs.keys())}")
        logger.info(f"ðŸŽ¬ tools from kwargs: {bool(tools)} ({len(tools) if tools else 0} tools)")
        if tools:
            logger.info(f"ðŸ” Tool names: {[t.get('function', {}).get('name', '?') if isinstance(t, dict) else '?' for t in tools]}")
        else:
            logger.info(f"âš ï¸ NO TOOLS in kwargs - Agno didn't pass any!")
        
        # Call the egile model with tools if available
        logger.info(f"ðŸŽ¬ Calling egile_model.generate()...")
        response = await self.egile_model.generate(egile_messages, tools=tools)
        logger.info(f"ðŸŽ¬ generate() returned, has tool_calls: {bool(response.tool_calls)}")
        
        # Log if tool calls were made
        if response.tool_calls:
            logger.info(f"ðŸŽ¯ Model returned {len(response.tool_calls)} tool calls!")
            for tc in response.tool_calls:
                logger.info(f"ðŸŽ¯ Tool call: {tc.get('function', {}).get('name', '?')}")
        else:
            logger.info(f"âš ï¸ Model did NOT return tool calls")
        
        return response.content

    async def ainvoke_stream(self, messages: list[Message], **kwargs: Any) -> AsyncIterator[ModelResponse]:
        """
        Stream the model response.
        
        Args:
            messages: List of Agno Message objects.
            **kwargs: Additional arguments from Agno. May include:
                - assistant_message: Message object to populate with streaming content
            
        Yields:
            ModelResponse objects containing string chunks of the response.
        """
        try:
            logger.info(f"ðŸŽ¬ AgnoAdapter.ainvoke_stream called!")
            logger.info(f"ðŸŽ¬ kwargs keys: {list(kwargs.keys())}")
            
            # Get the assistant message that Agno wants us to populate
            assistant_message = kwargs.get('assistant_message')
            accumulated_content = []
            
            # Convert Agno messages to egile format FIRST
            egile_messages = []
            
            # Handle different message formats
            if not isinstance(messages, list):
                messages = [messages]
                
            for i, msg in enumerate(messages):
                logger.debug(f"Processing message {i}: type={type(msg)}, value={msg}")
                
                if isinstance(msg, str):
                    # String message - treat as user message
                    egile_messages.append({"role": "user", "content": msg})
                elif isinstance(msg, dict):
                    # Already a dictionary
                    egile_messages.append(msg)
                elif hasattr(msg, 'role') and hasattr(msg, 'content'):
                    # Message object with role and content attributes
                    egile_messages.append({"role": msg.role, "content": msg.content})
                elif hasattr(msg, 'model_dump'):
                    # Pydantic model
                    egile_messages.append(msg.model_dump())
                else:
                    # Fallback - convert to string and treat as user message
                    egile_messages.append({"role": "user", "content": str(msg)})
            
            # Extract tools from kwargs if provided by Agno
            tools = kwargs.get('tools') or kwargs.get('functions')
            logger.info(f"ðŸŽ¬ tools from kwargs: {bool(tools)} ({len(tools) if tools else 0} tools)")
            
            # Log the existing tool_map from __init__
            logger.info(f"ðŸ“¦ Existing tool_map has {len(self._tool_map)} tools: {list(self._tool_map.keys())}")
            
            if tools:
                logger.info(f"ðŸ” Tool names: {[t.get('function', {}).get('name', '?') if isinstance(t, dict) else getattr(t, '__name__', '?') for t in tools]}")
                
                # Only add to tool_map if we don't already have the tools
                # DON'T reset self._tool_map - it was populated in __init__!
                for tool in tools:
                    if callable(tool):
                        # Tool is a function - use its name
                        tool_name = tool.__name__
                        if tool_name not in self._tool_map:
                            self._tool_map[tool_name] = tool
                            logger.info(f"ðŸ“¦ Added callable tool: {tool_name}")
                    elif isinstance(tool, dict):
                        # Tool is a dict spec - we already have the callable from __init__
                        tool_name = tool.get('function', {}).get('name')
                        if tool_name and tool_name not in self._tool_map:
                            logger.warning(f"âš ï¸ Tool {tool_name} is dict spec and not in tool_map")
                
                logger.info(f"ðŸ“¦ Final tool_map has {len(self._tool_map)} callable tools: {list(self._tool_map.keys())}")
            else:
                logger.info(f"âš ï¸ NO TOOLS in ainvoke_stream kwargs!")
            
            # CRITICAL: When tools are present, use generate() not stream()
            # Streaming doesn't properly handle tool calls - XAI returns tool_calls in the response
            # but streaming only yields text chunks
            if tools:
                logger.info(f"ðŸ”„ SWITCHING to generate() mode because tools are present")
                response = await self.egile_model.generate(egile_messages, tools=tools)
                
                # Check if model returned tool calls
                if response.tool_calls:
                    logger.info(f"ðŸŽ¯ Model returned {len(response.tool_calls)} tool calls!")
                    for tc in response.tool_calls:
                        logger.info(f"ðŸŽ¯   - {tc.get('function', {}).get('name', '?')}")
                    
                    # Set tool calls on the assistant message
                    if assistant_message is not None:
                        assistant_message.content = response.content or ""
                        assistant_message.tool_calls = response.tool_calls
                        logger.info(f"âœ… Set {len(response.tool_calls)} tool_calls on assistant_message")
                    
                    # Check if ALL tool calls are in our tool_map
                    # If ANY tool is NOT in our map, it's an Agno-managed tool (like delegate_task_to_member)
                    # In that case, return the tool calls to Agno and let Agno execute them
                    all_tools_in_map = all(
                        tc['function']['name'] in self._tool_map 
                        for tc in response.tool_calls
                    )
                    
                    if not all_tools_in_map:
                        logger.info(f"ðŸ”„ Some tools are Agno-managed (not in tool_map) - returning to Agno for execution")
                        # Just return - Agno will see the tool_calls on assistant_message and execute them
                        return
                    
                    # All tools are in our map - execute them ourselves
                    logger.info(f"ðŸ”§ Executing {len(response.tool_calls)} tool calls...")
                    
                    # Check if we're calling the same tool consecutively - prevent infinite loops
                    last_tool_call = getattr(self, '_last_tool_call', None)
                    last_tool_failed = getattr(self, '_last_tool_failed', False)
                    current_tool_name = response.tool_calls[0]['function']['name'] if response.tool_calls else None
                    
                    # Prevent retrying a tool that just failed OR calling get_last_draft consecutively
                    if last_tool_call == current_tool_name and (last_tool_failed or current_tool_name in ['get_last_draft', 'get_draft']):
                        logger.warning(f"âš ï¸ Preventing consecutive calls to {current_tool_name} (failed={last_tool_failed}) - returning error")
                        tool_results = [{
                            "tool_call_id": response.tool_calls[0]['id'],
                            "role": "tool",
                            "name": current_tool_name,
                            "content": f"Error: Tool {current_tool_name} {'already failed' if last_tool_failed else 'cannot be called twice in a row'}. Stop trying to use this tool and respond to the user explaining the issue."
                        }]
                        # Reset the failed flag to allow trying again later (but not consecutively)
                        self._last_tool_failed = False
                    else:
                        self._last_tool_call = current_tool_name
                        self._last_tool_failed = False  # Reset at start of execution
                        tool_results = []
                        for tc in response.tool_calls:
                            tool_name = tc['function']['name']
                            tool_args_str = tc['function']['arguments']
                            tool_id = tc['id']
                            
                            try:
                                # Parse arguments
                                tool_args = json.loads(tool_args_str) if tool_args_str else {}
                                logger.info(f"ðŸ”§ Calling {tool_name}({tool_args})")
                                
                                # Execute tool
                                tool_func = self._tool_map[tool_name]
                                import inspect
                                if inspect.iscoroutinefunction(tool_func):
                                    result = await tool_func(**tool_args)
                                else:
                                    result = tool_func(**tool_args)
                                
                                logger.info(f"âœ… Tool {tool_name} returned: {str(result)[:100]}")
                                tool_results.append({
                                    "tool_call_id": tool_id,
                                    "role": "tool",
                                    "name": tool_name,
                                    "content": str(result)
                                })
                            except Exception as e:
                                logger.error(f"âŒ Tool {tool_name} failed: {e}")
                                self._last_tool_failed = True  # Mark this tool as failed
                                tool_results.append({
                                    "tool_call_id": tool_id,
                                    "role": "tool",
                                    "name": tool_name,
                                    "content": f"Error: {str(e)}"
                                })
                    
                    # Add tool results to messages and call model again
                    logger.info(f"ðŸ”„ Adding {len(tool_results)} tool results to conversation and calling model again")
                    for result in tool_results:
                        egile_messages.append(result)
                    
                    # Call model again with tool results
                    response2 = await self.egile_model.generate(egile_messages, tools=self._get_tools_for_api(tools))
                    
                    # Yield the final response
                    if response2.content:
                        for chunk in response2.content.split():
                            yield ModelResponse(content=chunk + " ", role="assistant")
                    
                    if assistant_message is not None:
                        assistant_message.content = response2.content
                    
                    return
                else:
                    logger.info(f"âš ï¸ Model did NOT return tool calls despite tools being present")
                    # Yield the text response
                    if response.content:
                        yield ModelResponse(content=response.content, role="assistant")
                    if assistant_message is not None:
                        assistant_message.content = response.content
                return
            
            logger.debug(f"Converted to egile messages: {egile_messages}")
            logger.debug(f"Assistant message before streaming: {assistant_message}")
            
            # Stream from the egile model WITH TOOLS
            logger.info(f"ðŸŽ¬ Calling egile_model.stream() with {len(tools) if tools else 0} tools...")
            async for chunk in self.egile_model.stream(egile_messages, tools=tools):
                # Accumulate content if we have an assistant message to populate
                if assistant_message is not None:
                    accumulated_content.append(chunk)
                
                # Yield ModelResponse object instead of raw string
                yield ModelResponse(content=chunk, role="assistant")
            
            # After streaming completes, populate the assistant message with accumulated content
            # Agno expects us to set the content field with the complete response
            if assistant_message is not None and accumulated_content:
                final_content = "".join(accumulated_content)
                logger.debug(f"Setting assistant_message.content to: {final_content[:100]}...")
                assistant_message.content = final_content
                logger.debug(f"Assistant message after streaming: role={assistant_message.role}, content set={assistant_message.content is not None}")
                
        except Exception as e:
            logger.error(f"Error in ainvoke_stream: {e}", exc_info=True)
            raise

    def _parse_provider_response(self, response: Any) -> ModelResponse:
        """
        Parse provider response - converts response to ModelResponse.
        This is used by Agno's framework.
        """
        if isinstance(response, ModelResponse):
            return response
        # Convert string or other response to ModelResponse
        return ModelResponse(content=str(response), role="assistant")

    def _parse_provider_response_delta(self, delta: Any) -> ModelResponse:
        """
        Parse provider response delta for streaming - converts delta to ModelResponse.
        This is used by Agno's framework for streaming responses.
        """
        if isinstance(delta, ModelResponse):
            return delta
        # Convert string or other delta to ModelResponse
        return ModelResponse(content=str(delta), role="assistant")
        return str(delta)
